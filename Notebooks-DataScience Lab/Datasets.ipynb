{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking your datasets for the data science lab (examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing your tracker (PyPads)\n",
    "First you have to install pypads-padre which has pypads as a dependency\n",
    "\n",
    "    pip install pypads-padre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypads.app.base import PyPads\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "tracker = PyPads(uri=\"http://mlflow.padre-lab.eu\", autostart=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- load the datasets and test if it works\n",
    "- do random tests on the datasets with splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([5, 5, 0, ..., 1, 2, 2]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([7, 7, 2, ..., 8, 9, 9]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.start_track(experiment_name= \"3D MNIST\")\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Loading and tracking your dataset\n",
    "path = \"data/3d-mnist/full_dataset_vectors.h5\"\n",
    "@tracker.decorators.dataset(name=\"3DMNIST\", target_columns=[-1])\n",
    "def load_3d_mnist(path):\n",
    "    \"\"\"\n",
    "    The aim of this dataset is to provide a simple way to get started with 3D computer vision problems such as 3D shape recognition.\n",
    "\n",
    "    Accurate 3D point clouds can (easily and cheaply) be adquired nowdays from different sources:\n",
    "\n",
    "     - RGB-D devices: Google Tango, Microsoft Kinect, etc.\n",
    "     - Lidar.\n",
    "     - 3D reconstruction from multiple images.\n",
    "\n",
    "    However there is a lack of large 3D datasets (you can find a good one here based on triangular meshes); it's especially hard to find datasets based on point clouds (wich is the raw output from every 3D sensing device).\n",
    "\n",
    "    This dataset contains 3D point clouds generated from the original images of the MNIST dataset to bring a familiar introduction to 3D to people used to work with 2D datasets (images).\n",
    "\n",
    "    The full dataset is splitted into arrays:\n",
    "\n",
    "    X_train (10000, 4096)\n",
    "    y_train (10000)\n",
    "    X_test(2000, 4096)\n",
    "    y_test (2000)\n",
    "    \n",
    "    data is the concatenation of X_train, X_test, y_train, y_test (12000, 4097)\n",
    "    \n",
    "    :return data \n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as hf:\n",
    "        X_train, y_train = hf[\"X_train\"][:], hf[\"y_train\"][:]\n",
    "        X_test, y_test = hf[\"X_test\"][:], hf[\"y_test\"][:]\n",
    "        train_data = np.concatenate([X_train, y_train.reshape(len(y_train), 1)], axis=1)\n",
    "        test_data = np.concatenate([X_test, y_test.reshape(len(y_test), 1)], axis=1)\n",
    "        data = np.concatenate([train_data, test_data], axis=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "data = load_3d_mnist(path)\n",
    "\n",
    "# Tracking your train and test splits: in this simple case we follow the original data train : (10000) test: (2000)\n",
    "\n",
    "@tracker.decorators.splitter()\n",
    "def splitter(data, index=10000):\n",
    "    import numpy as np\n",
    "    idx = np.arange(data.shape[0])\n",
    "    return idx[:index], idx[index:]\n",
    "\n",
    "train, test = splitter(data)\n",
    "# Do and log stuff\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.classification import f1_score\n",
    "\n",
    "X_train, y_train = data[train,:-1],data[train,-1]\n",
    "X_test, y_test = data[test,:-1],data[test,-1]\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(preds,y_test)\n",
    "\n",
    "print(\"F1_score: \", str(f1))\n",
    "\n",
    "# end_run\n",
    "tracker.api.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Covid-19 tweets example\n",
    "tracker.start_track(experiment_name= \"Covid-19 Tweets\")\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# Loading and tracking your dataset\n",
    "path = \"data/covid-19-tweets/covid19_tweets.csv\"\n",
    "@tracker.decorators.dataset(name=\"Covid-19 Tweets\")\n",
    "def load_covid_tweets(path):\n",
    "    \"\"\"\n",
    "    These tweets are collected using Twitter API and a Python script. \n",
    "    A query for this high-frequency hashtag (#covid19) is run on a daily basis for a certain time period, to collect a larger number of tweets samples.\n",
    "    The collection script can be found here: https://github.com/gabrielpreda/covid-19-tweets\n",
    "    \n",
    "    :return dataframe \n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_covid_tweets(path)\n",
    "\n",
    "# Do and log stuff\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "# end_run\n",
    "tracker.api.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypads-padre-3.7",
   "language": "python",
   "name": "pypads-padre-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
